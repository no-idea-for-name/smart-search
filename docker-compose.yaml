name: smart-search
services:
  search-server:
    image: search-server:0.1.1
    restart: unless-stopped
    ports:
      - 5000:5000
    networks:
      - elastic_network
    environment:
      - ES_HOST=elasticsearch
      - ELASTIC_PASSWORD=test123
      - EMBEDDING_MODEL=nomic-embed-text
      - OLLAMA_HOST=ollama
      - LANGCHAIN_API_KEY=
      - LANGCHAIN_TRACING_V2=false
      - LANGCHAIN_PROJECT=smart-search
    deploy:
      resources:
        limits:
          memory: 1gb
    depends_on:
      - elasticsearch
      - ollama

  knowledge-manager:
    image: knowledge-manager:0.1.2
    restart: unless-stopped
    ports:
      - 6000:5000
    networks:
      - elastic_network
    environment:
      - ES_HOST=elasticsearch
      - ELASTIC_PASSWORD=test123
      - EMBEDDING_MODEL=nomic-embed-text
      - OLLAMA_HOST=ollama
    volumes:
      - knowledge_manager_data:/app/data/
    deploy:
      resources:
        limits:
          memory: 1gb
    depends_on:
      - elasticsearch
      - ollama

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.3
    restart: always
    networks:
      - elastic_network
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    environment:
      - ELASTIC_PASSWORD=test123
      - xpack.security.enabled=false
      - bootstrap.memory_lock=true
      - discovery.type=single-node
    expose:
      - 9200
    deploy:
      resources:
        limits:
          memory: 6gb

  ollama:
    volumes:
      - ollama_data:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    expose:
      - 11434
    environment:
      - gpus=all
    networks:
      - elastic_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

networks:
  elastic_network:
    driver: bridge

volumes:
  ollama_data:
  elasticsearch_data:
  knowledge_manager_data: